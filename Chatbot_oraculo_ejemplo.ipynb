{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpJLvjLfodbizFOzCaTSia",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vshalisko/PythonIntro/blob/main/Chatbot_oraculo_ejemplo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ¿Que tan facil es crear un Chatbot con Python?\n",
        "\n",
        "> It will take exactly 4 months, 3 weeks, 2 days, 1 hour, 46 minutes and 15 seconds to learn everything you need to know to build a simple chatbot. (opinión de un usuario de Reddit) https://www.reddit.com/r/learnpython/comments/1dc80lz/making_simple_chatbot/\n",
        "\n",
        "### Respuesta: Depende del tipo de Chatbot\n",
        "\n"
      ],
      "metadata": {
        "id": "odXzBYuNuISA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a crear un Chatbot simple inspirado en código en un proyecto introductorio de Hyperskill\n",
        "* https://hyperskill.org/projects/97\n",
        "\n",
        "Soluciones:\n",
        "* https://github.com/syyynth/hyperskill/tree/main/python/0097%20-%20Simple%20Chatty%20Bot%20(Python)\n",
        "* https://github.com/Mathesh099/Simple-Chatty-Bot\n",
        "\n",
        "\n",
        "Adicionalmente (en la etapa avanzada del proyecto) vamos a ampliar nuestro chatbot con los los componentes que usan la biblioteca NLTK, similar a un ejemplo disponible en:\n",
        "* https://planetachatbot.com/construyendo-chatbot-simple-desde-cero-en-python-usando-nltk/\n",
        "\n"
      ],
      "metadata": {
        "id": "y3DFJx5BuO5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa básica del proyecto\n",
        "### Los elementos incluidos en siguientes apartados son obligatorios para entrega de la tarea"
      ],
      "metadata": {
        "id": "ligaHTpZP4Jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vamos a saludar el usuario\n",
        "\n",
        "Para realizar este apartado se requiere usar las funciones `print()`, `input()`, `str()`, además, se requiere conocer la operación para concatenar las cadenas de texto."
      ],
      "metadata": {
        "id": "_wI4EOtGQ7Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('¡Hola! Soy un ChatBot.')\n",
        "print('Me crearon en 2025 como parte de un ejercicio.')\n",
        "print('¿Y tu nombre cual es?.')\n",
        "nombre_usuario = str(input())\n",
        "print('¡Me encanta tu nombre, ' + nombre_usuario + \"!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrRx_wGKQF-u",
        "outputId": "d4fb3f57-c506-422f-8cbd-9c860d929147"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Hola! Soy un ChatBot.\n",
            "Me crearon en 2025 como parte de un ejercicio.\n",
            "¿Y tu nombre cual es?.\n",
            "Slava\n",
            "¡Me encanta tu nombre, Slava!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ahora vamos a adivinar edad del usuario. Para esto le vamos a hacer algunas preguntas\n",
        "\n",
        "Para realizar este apartado se requiere usar las funciones `print()`, `input()`, `int()`, se requiere conocer las operación matematicas con los números enteros, incluyendo el operador  módulo `%` que permite calcular el remanente de la división. Además, se requiere conocer como podemos definir una función y llamarla."
      ],
      "metadata": {
        "id": "cE4WtHWERAYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adivinar_edad():\n",
        "    print('Me gustaria adivinar tu edad, ' + nombre_usuario + '.')\n",
        "    print('Para esto voy a hacer tres preguntas.')\n",
        "\n",
        "    rem3 = int(input('¿Cual es el remanente de división de tu edad en 3?\\n'))\n",
        "    rem5 = int(input('¿Cual es el remanente de división de tu edad en 5?\\n'))\n",
        "    rem7 = int(input('¿Cual es el remanente de división de tu edad en 7?\\n'))\n",
        "    age = (rem3 * 70 + rem5 * 21 + rem7 * 15) % 105\n",
        "\n",
        "    print(\"Creo que tu edad es \" + str(age) + \". ¡Es un momento maravilloso para estudiar Python!\")\n",
        "\n",
        "adivinar_edad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khfmTEIgRMOv",
        "outputId": "26a18b81-3807-4959-c9ca-4e221645dd61"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Me gustaria adivinar tu edad, Slava.\n",
            "Para esto voy a hacer tres preguntas.\n",
            "¿Cual es el remanente de división de tu edad en 3?\n",
            "3\n",
            "¿Cual es el remanente de división de tu edad en 5?\n",
            "2\n",
            "¿Cual es el remanente de división de tu edad en 7?\n",
            "5\n",
            "Creo que tu edad es 12. ¡Es un momento maravilloso para estudiar Python!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa avanzada del proyecto\n",
        "### Todo lo que se presenta a continuación es opcional, no es obligatorio incluirlo a su producto entregable. Sin embargo, tambien se puede incluirlo, ya que permite hacer nuestro chatbot más divertido. En todo caso vamos a revisar como funciona esta parte de código.\n",
        "\n",
        "* En principio vamos a instalar la biblioteca **gensim** en el entorno virtual de Python, pporque no esta incluida par default en el entorno de **Colab**.\n",
        "\n",
        "* Nota: Al momento de instalar la biblioteca por primera vez surante la sesion se requiere permitir reiniciar la sesión de **Colab**."
      ],
      "metadata": {
        "id": "ey594OBdB_SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install gensim"
      ],
      "metadata": {
        "id": "mOzOer-n4T-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b797d87-5e9e-428a-df27-57ac123d840e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Vamos a cargar los componentes (bibliotecas) **re**, **nltk**, **numpy**, y algunos componentes de **gensim** y **sklearn**"
      ],
      "metadata": {
        "id": "5rEu6rvnInAm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "qYc7JdqruAfl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Vamos a descargar las bases de datos de **nltk**"
      ],
      "metadata": {
        "id": "Q-CmBv5OIxIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6RgHEQmrbuS",
        "outputId": "fa5429dc-5b80-4e39-a5e3-c882ecc92939"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Vamos a cargar las palabras de español incluidas en la lista de **stopwprds**"
      ],
      "metadata": {
        "id": "QbEeHFdHJ30O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_sw = set(stopwords.words('spanish'))\n",
        "#print(spanish_sw)"
      ],
      "metadata": {
        "id": "iEDWqGn-zsW2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Vamos a conectar **Google Drive** del usuario (de alla vamos a tomar la base de datos de frases celebres)"
      ],
      "metadata": {
        "id": "AJKIGpOuIzSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "u0_fpNpmuldh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34454a60-0ceb-4449-a14d-e3465638e981"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Vamos a leer el archivo con la base de datos de frases celebres desde **Google Drive**"
      ],
      "metadata": {
        "id": "8VqicodWmHLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Colab Data/'\n",
        "file = 'frases_celebres_seleccion.txt'\n",
        "\n",
        "frases = ''\n",
        "with open(path + file, 'r', errors = 'ignore') as f:\n",
        "  frases = f.read()\n",
        "  #print(frases)"
      ],
      "metadata": {
        "id": "_fmwLjIeusfO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ahora comenzamos con el uso de la biblioteca **nltk** para procesar la base de datos de fráes celebres\n",
        "Para pre-procesar la base de datos de frases célebres vamo a hacer lo siguiente:\n",
        "1. Convertir todo texto a registro bajo\n",
        "2. Separar las frases para conformar una lista\n",
        "3. Separar palabras (opcional)\n",
        "4. Solo para fines de referencia vamo a presentar en conteo de frases incluidos, ejemplos de algunos frases, y el npumero de palabras en la base de datos de frases célebres"
      ],
      "metadata": {
        "id": "GfdJI-GUNYrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convertir texto plano a lista de frases\n",
        "onlysent_tokens = nltk.sent_tokenize(frases)\n",
        "# reemplazar simbolos de nueva linea ocn espacios\n",
        "onlysent_tokens = [sentence.replace('\\n', ' ') for sentence in onlysent_tokens]\n",
        "\n",
        "# generar una copia de texto con en lowercase\n",
        "frases_lc = frases.lower()\n",
        "# convertir texto a lista de palabras\n",
        "word_tokens = nltk.word_tokenize(frases_lc)\n",
        "\n",
        "print(\"\\nNúmero de frases célebres en la base de datos:\")\n",
        "print(len(onlysent_tokens))\n",
        "\n",
        "print(\"\\nEjemplo de frases celebres:\")\n",
        "print(onlysent_tokens[0:3])\n",
        "\n",
        "print(\"\\nNúmero de palabras en labase de datos de frases célebres:\")\n",
        "print(len(word_tokens))"
      ],
      "metadata": {
        "id": "RXyVtyVruWRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf4e4d3-d289-47f8-8e81-1e7a51c18d27"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Número de frases célebres en la base de datos:\n",
            "639\n",
            "\n",
            "Ejemplo de frases celebres:\n",
            "['¿Encontraría a la Maga?', 'Tan de vez en cuando uno tiene ganas de encontrarse a sí mismo.', 'A buen hambre, no hay pan duro.']\n",
            "\n",
            "Número de palabras en labase de datos de frases célebres:\n",
            "7329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adicional a **nltk** requerimos la bibliotica **gensim** para utilizar el modelo **Word2Vec** a partir de la base de datos de frases célebres\n",
        "\n",
        "Trata de un modelo donde palabras se colocan en un espacio de factores para representar el vector de su significado, derivado de otras palabras que se encuentran en su vecindad.\n",
        "\n",
        "En la web existe la información extensa sobre este modelo, por ejemplo:\n",
        "* https://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/\n",
        "* https://kavita-ganesan.com/how-to-incorporate-phrases-into-word2vec-a-text-mining-approach/\n",
        "* https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
        "\n",
        "En principio vamos a preparar datos para su uso en **Word2Vec**"
      ],
      "metadata": {
        "id": "Ms8cOVP8KEqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesar texto para generar el modelo Word2Vec\n",
        "\n",
        "# quitar los simbolos de puntuación\n",
        "# convertir palabras a letras minusculas\n",
        "# y separar frases en listas de palabras\n",
        "corpus_sentences = [re.sub(r'[^\\w\\s]', '', sentence.lower()).split() for sentence in onlysent_tokens]\n",
        "\n",
        "#print(type(corpus_sentences))\n",
        "#print(len(corpus_sentences))\n",
        "#print(corpus_sentences[0:3])\n",
        "\n",
        "# funcion para eliminar stopwords\n",
        "def remove_stopwords(sentence_words, sw):\n",
        "  filtered_words = [word for word in sentence_words if word not in sw]\n",
        "  return filtered_words\n",
        "\n",
        "# eliminar stopwords de la base de datos de frases célebres\n",
        "filtered_sentences = []\n",
        "for sentence in corpus_sentences:\n",
        "  filtered_sentence = remove_stopwords(sentence, spanish_sw)\n",
        "  filtered_sentences.append(filtered_sentence)\n",
        "\n",
        "#print(type(filtered_sentences))\n",
        "#print(len(filtered_sentences))\n",
        "#print(filtered_sentences[0:3])"
      ],
      "metadata": {
        "id": "kA7myyaAf4ej"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a entrenar el modelo **Word2Vec** con nuestros datos"
      ],
      "metadata": {
        "id": "O6dpRaK5gLTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo Word2Vec\n",
        "model = Word2Vec(min_count=1,\n",
        "                     window=6,\n",
        "                     vector_size=300,\n",
        "                     sample=6e-5,\n",
        "                     alpha=0.03,\n",
        "                     min_alpha=0.0007,\n",
        "                     negative=20,\n",
        "                     workers=4)\n",
        "\n",
        "model.build_vocab(filtered_sentences, progress_per=1000)\n",
        "model.train(filtered_sentences, total_examples=model.corpus_count, epochs=30, report_delay=1)\n",
        "\n",
        "# Entrenar el modelo Word2Vec (form simplificada)\n",
        "#model = Word2Vec(sentences=filtered_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "print(\"\\nCaracteristicas del modelo Word2Vec\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwHAbRfc1Irh",
        "outputId": "1f02f5bf-4f5c-4257-fc9e-b343749e1f8f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Caracteristicas del modelo Word2Vec\n",
            "Word2Vec<vocab=1534, vector_size=300, alpha=0.03>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ahora podemos regresar a interactuar con el usuario en marco de nuestro ChatBot\n",
        "* Preguntar al usuario por una frase"
      ],
      "metadata": {
        "id": "EXgfCo-tKlPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = str(input(nombre_usuario + \", introduce su pregunta o algo que te gustaria discutir: \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKTY7I100rLt",
        "outputId": "4320f207-b6f5-4ed3-ad11-159e0f033d1a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Slava, introduce su pregunta o algo que te gustaria discutir: Me gustaria saber como leer los libros en nuestros tiempos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Comparar la frase con la base de datos de frases celebres y buscar la frase celebre con el significado mas cercana a la frase proporcionada por el usuario"
      ],
      "metadata": {
        "id": "LIryo4nGKxNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Funcion para construir el vector de una frase\n",
        "def get_sentence_vector(words, model):\n",
        "\n",
        "    # determinar el vector de cada palabra en la frase en forma de lista\n",
        "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "\n",
        "    # en caso que vector es vacio generar el vector de ceros y regresarlo\n",
        "    if not word_vectors:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "    # en caso que vector no es vacio generar un promedio y regresarlo\n",
        "    return np.mean(word_vectors, axis=0)\n",
        "\n",
        "# Procesar la pregunta del usuario para construir su vector\n",
        "user_words = re.sub(r'[^\\w\\s]', '', user_input.lower()).split()\n",
        "filtered_user_input = remove_stopwords(user_words, spanish_sw)\n",
        "user_input_vector = get_sentence_vector(filtered_user_input, model)\n",
        "\n",
        "print(\"Pregunta de \" + nombre_usuario + \": \" + str(user_input))\n",
        "#print(\"Pregunta del ususrio filtrada: \" + str(filtered_user_input))\n",
        "#print(\"Vector del modelo:\")\n",
        "#print(user_input_vector)\n",
        "\n",
        "# Encontrar la frase mas cercana por el signiicado entre frases célebres\n",
        "most_similar_sentence = \"\"\n",
        "max_similarity = -1\n",
        "\n",
        "for i, sentence in enumerate(filtered_sentences):\n",
        "    sentence_vector = get_sentence_vector(sentence, model)\n",
        "    if np.linalg.norm(user_input_vector) != 0 and np.linalg.norm(sentence_vector) != 0:\n",
        "        similarity = cosine_similarity([user_input_vector], [sentence_vector])[0][0]\n",
        "        if similarity > max_similarity:\n",
        "            max_similarity = similarity\n",
        "            most_similar_sentence = onlysent_tokens[i]\n",
        "\n",
        "\n",
        "if not most_similar_sentence:\n",
        "  print(nombre_usuario + \", lamento, pero no tengo nada que responder en esta ocasión\")\n",
        "else:\n",
        "  print(\"La respuesta es: \" + most_similar_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5cVy7YJkmYX",
        "outputId": "5c1306e0-dcda-4497-ab5a-8dee05c91995"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta de Slava: Me gustaria saber como leer los libros en nuestros tiempos\n",
            "La respuesta es: La medida última de un hombre no es dónde se encuentra en momentos de comodidad y conveniencia, sino dónde se encuentra en tiempos de desafío y controversia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Es hora de despedir"
      ],
      "metadata": {
        "id": "Cs6QtM5er1k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Hasta la proxima, ' + nombre_usuario + '!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGSdFEvFr3Ft",
        "outputId": "5a281543-c212-41da-e7c0-7f5f1c7e2d82"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasta la proxima, Slava!\n"
          ]
        }
      ]
    }
  ]
}